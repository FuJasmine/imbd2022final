{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Module\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files name\n",
    "path1 = 'train1/'\n",
    "lenght = 47\n",
    "\n",
    "sg_files = []\n",
    "spike_files = []\n",
    "\n",
    "for i in range(1, lenght):\n",
    "    sg_files.append( path1 + str(i) + '_sg.csv')\n",
    "    spike_files.append( path1 + str(i) + '_spike.csv')\n",
    "    \n",
    "print(sg_files)\n",
    "print(spike_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and seperate each feature to do data preprocessing\n",
    "s = time.time()\n",
    "print('Concating sg...')\n",
    "sg_data = [pd.read_csv(i) for i in sg_files]\n",
    "\n",
    "print('Concating spike')\n",
    "spike_data = [pd.read_csv(i) for i in spike_files]\n",
    "\n",
    "print('Reading MaxWear')\n",
    "output = pd.read_csv(path1+'00_Wear_data.csv')\n",
    "output.drop(['Indea_mask'], axis=\"columns\", inplace=True)\n",
    "\n",
    "print('sg_data: ' + str(len(sg_data)))\n",
    "print('spike_data: ' + str(len(spike_data)))\n",
    "\n",
    "print('cost time:', time.time() - s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature index\n",
    "Sg_Feature_Index = ['A', 'B', 'C', 'D', 'E', 'F', 'H', 'I']\n",
    "Spike_Feature_Index = ['A', 'B', 'C', 'D']\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "# Concat data\n",
    "sg_data_concat = pd.concat(sg_data, axis=1)\n",
    "spike_data_concat = pd.concat(spike_data, axis=1)\n",
    "\n",
    "print('sg_data_concat' + str(sg_data_concat.shape))\n",
    "print('spike_data_concat' + str(spike_data_concat.shape))\n",
    "\n",
    "# Create dict then use the last value of that column to fill in to get a same dimention in one featrue(column)\n",
    "sg = {}\n",
    "spike = {}\n",
    "\n",
    "for i in Sg_Feature_Index:\n",
    "  print('fillna sg_' + str(i) + '...')\n",
    "  data = sg_data_concat[i].copy()\n",
    "  for j in range(0, lenght-1):\n",
    "      initial_data = data.iloc[:, j]\n",
    "      if True in initial_data.isnull().values:\n",
    "          last_value = initial_data[np.where(\n",
    "              initial_data.isnull().values == True)[0][0]-1]\n",
    "          data.iloc[:, j] = sg_data_concat[i].iloc[:, j].fillna(last_value)\n",
    "          sg_data_concat[i] = data\n",
    "  sg['sg_' + str(i)] = sg_data_concat[i]\n",
    "\n",
    "for i in Spike_Feature_Index:\n",
    "  print('fillna spike_' + str(i) + '...')\n",
    "  data = spike_data_concat[i].copy()\n",
    "  for j in range(0, lenght-1):\n",
    "      initial_data = data.iloc[:, j]\n",
    "      if True in initial_data.isnull().values:\n",
    "          last_value = initial_data[np.where(\n",
    "              initial_data.isnull().values == True)[0][0]-1]\n",
    "          data.iloc[:, j] = spike_data_concat[i].iloc[:, j].fillna(last_value)\n",
    "          spike_data_concat[i] = data\n",
    "  spike['spike_' + str(i)] = spike_data_concat[i]\n",
    "\n",
    "print('cost time:', time.time() - s)\n",
    "\n",
    "print(sg.keys())\n",
    "print(spike.keys())\n",
    "\n",
    "# np.save()\n",
    "sg_feture = list(sg.keys())\n",
    "spike_feture = list(spike.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "for i in spike_feture:\n",
    "    a = np.transpose(spike[i].values).tolist()\n",
    "    for j in range(len(a)):\n",
    "        index = range(3, len(a[j])-1, 5)\n",
    "        value = [(a[j][k-1] + a[j][k])/2 for k in index]\n",
    "        a[j] = np.insert(a[j], index, value)\n",
    "    spike[i] =  np.array(a)\n",
    "    print(str(i) + str(spike[i].shape))\n",
    "print('cost time: ', time.time() - s)\n",
    "\n",
    "s = time.time()\n",
    "for i in spike_feture:\n",
    "    a = np.transpose(spike[i])\n",
    "    df = pd.DataFrame(a)\n",
    "    select_index = [i for i in range(0, spike[i].shape[1], 3)]\n",
    "    spike[i] = df.iloc[select_index, :].reset_index(drop=True)\n",
    "    print(str(i) + str(spike[i].shape))\n",
    "print('cost time: ', time.time() - s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sg_feture:\n",
    "    sg[i] = np.array(sg[i])\n",
    "    np.save(i, sg[i])\n",
    "for i in spike_feture:\n",
    "    spike[i] = np.array(spike[i])\n",
    "    np.save(i, spike[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25d55898efc93ddab13c6ef669342cf4b20d71dee37db728c7ac40afe433fc25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
